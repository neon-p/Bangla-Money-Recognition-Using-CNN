{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import csv\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('money_label.csv').values\n",
    "train=pd.DataFrame(train,columns='img_name img_label'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = []\n",
    "def img_to_array(number,iteration):\n",
    "    for i in range(iteration):\n",
    "        img = image.load_img('bangla-money/Training/'+str(number)+'/'+str(number)+'_'+str(i)+'.jpg', target_size=(120,250,1), color_mode=\"grayscale\")\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255\n",
    "        train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_array(1,101)\n",
    "img_to_array(2,213)\n",
    "img_to_array(5,213)\n",
    "img_to_array(10,213)\n",
    "img_to_array(20,173)\n",
    "img_to_array(50,213)\n",
    "img_to_array(100,208)\n",
    "img_to_array(500,136)\n",
    "img_to_array(1000,167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "category=[1,2,3,4,5,6,7,8,9]\n",
    "label_encoder=LabelEncoder()\n",
    "int_encoded=label_encoder.fit_transform(category)\n",
    "onehot_encoder=OneHotEncoder(sparse=False)\n",
    "int_encoded= int_encoded.reshape(len(int_encoded),1)\n",
    "onehot_encoded=onehot_encoder.fit_transform(int_encoded)\n",
    "print(len(onehot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_label=[]\n",
    "for i in train['img_label']:\n",
    "    if i == 1:\n",
    "        vectorize_label.append(onehot_encoded[0])\n",
    "    elif i == 2:\n",
    "        vectorize_label.append(onehot_encoded[1])\n",
    "    elif i == 5:\n",
    "        vectorize_label.append(onehot_encoded[2])\n",
    "    elif i == 10:\n",
    "        vectorize_label.append(onehot_encoded[3])\n",
    "    elif i == 20:\n",
    "        vectorize_label.append(onehot_encoded[4])\n",
    "    elif i == 50:\n",
    "        vectorize_label.append(onehot_encoded[5])\n",
    "    elif i == 100:\n",
    "        vectorize_label.append(onehot_encoded[6])\n",
    "    elif i == 500:\n",
    "        vectorize_label.append(onehot_encoded[7])\n",
    "    elif i == 1000:\n",
    "        vectorize_label.append(onehot_encoded[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "vectorize_label=np.array(vectorize_label)\n",
    "print(vectorize_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=vectorize_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1637, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its not an Image\n"
     ]
    }
   ],
   "source": [
    "test_img=[]\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('bangla-money/Testing/'):\n",
    "    for filename in range(len(filenames)):\n",
    "        if filenames[filename]==\"Thumbs.db\":\n",
    "            print(\"Its not an Image\")\n",
    "        else:\n",
    "            img = image.load_img('bangla-money/Testing/'+filenames[filename], target_size=(120,250,1), color_mode=\"grayscale\")\n",
    "            img = image.img_to_array(img)\n",
    "            img = img/255\n",
    "            test_img.append(img)\n",
    "test_img=np.array(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(120,250,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(9, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1309 samples, validate on 328 samples\n",
      "Epoch 1/10\n",
      "1309/1309 [==============================] - 101s 77ms/step - loss: 2.1957 - accuracy: 0.1146 - val_loss: 2.1785 - val_accuracy: 0.1098\n",
      "Epoch 2/10\n",
      "1309/1309 [==============================] - 96s 73ms/step - loss: 2.1825 - accuracy: 0.1245 - val_loss: 2.1760 - val_accuracy: 0.1098\n",
      "Epoch 3/10\n",
      "1309/1309 [==============================] - 101s 77ms/step - loss: 2.1817 - accuracy: 0.1413 - val_loss: 2.1709 - val_accuracy: 0.1280\n",
      "Epoch 4/10\n",
      "1309/1309 [==============================] - 97s 74ms/step - loss: 2.1539 - accuracy: 0.1436 - val_loss: 2.1877 - val_accuracy: 0.1250\n",
      "Epoch 5/10\n",
      "1309/1309 [==============================] - 96s 73ms/step - loss: 1.7482 - accuracy: 0.3743 - val_loss: 1.0081 - val_accuracy: 0.7409\n",
      "Epoch 6/10\n",
      "1309/1309 [==============================] - 97s 74ms/step - loss: 0.8169 - accuracy: 0.7426 - val_loss: 0.3879 - val_accuracy: 0.8841\n",
      "Epoch 7/10\n",
      "1309/1309 [==============================] - 96s 73ms/step - loss: 0.3461 - accuracy: 0.9015 - val_loss: 0.1925 - val_accuracy: 0.9451\n",
      "Epoch 8/10\n",
      "1309/1309 [==============================] - 105s 80ms/step - loss: 0.1957 - accuracy: 0.9496 - val_loss: 0.1520 - val_accuracy: 0.9573\n",
      "Epoch 9/10\n",
      "1309/1309 [==============================] - 102s 78ms/step - loss: 0.1428 - accuracy: 0.9603 - val_loss: 0.1378 - val_accuracy: 0.9604\n",
      "Epoch 10/10\n",
      "1309/1309 [==============================] - 100s 76ms/step - loss: 0.0743 - accuracy: 0.9794 - val_loss: 0.1132 - val_accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "cnn=model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=model.predict(test_img,batch_size=None,verbose=0,steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# model=load_model('CNN_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20\n",
      "1 1000\n",
      "2 1000\n",
      "3 100\n",
      "4 1000\n",
      "5 1000\n",
      "6 1000\n",
      "7 1000\n",
      "8 1000\n",
      "9 1000\n",
      "10 1000\n",
      "11 1000\n",
      "12 1000\n",
      "13 1000\n",
      "14 1000\n",
      "15 50\n",
      "16 1000\n",
      "17 1000\n",
      "18 1000\n",
      "19 100\n",
      "20 1000\n",
      "21 1000\n",
      "22 1000\n",
      "23 1000\n",
      "24 1000\n",
      "25 1000\n",
      "26 1000\n",
      "27 1000\n",
      "28 5\n",
      "29 1000\n",
      "30 1000\n",
      "31 1000\n",
      "32 1000\n",
      "33 1000\n",
      "34 1000\n",
      "35 20\n",
      "36 1000\n",
      "37 1000\n",
      "38 1000\n",
      "39 1000\n",
      "40 100\n",
      "41 1000\n",
      "42 1000\n",
      "43 50\n",
      "44 1000\n",
      "45 1000\n",
      "46 1000\n",
      "47 100\n",
      "48 1000\n",
      "49 1000\n",
      "50 1000\n",
      "51 1000\n",
      "52 100\n",
      "53 100\n",
      "54 100\n",
      "55 100\n",
      "56 100\n",
      "57 100\n",
      "58 100\n",
      "59 100\n",
      "60 100\n",
      "61 100\n",
      "62 100\n",
      "63 100\n",
      "64 100\n",
      "65 100\n",
      "66 100\n",
      "67 100\n",
      "68 100\n",
      "69 100\n",
      "70 100\n",
      "71 100\n",
      "72 100\n",
      "73 50\n",
      "74 100\n",
      "75 100\n",
      "76 100\n",
      "77 100\n",
      "78 100\n",
      "79 100\n",
      "80 100\n",
      "81 100\n",
      "82 100\n",
      "83 100\n",
      "84 100\n",
      "85 100\n",
      "86 100\n",
      "87 100\n",
      "88 100\n",
      "89 100\n",
      "90 10\n",
      "91 10\n",
      "92 10\n",
      "93 10\n",
      "94 10\n",
      "95 10\n",
      "96 5\n",
      "97 10\n",
      "98 50\n",
      "99 10\n",
      "100 10\n",
      "101 50\n",
      "102 10\n",
      "103 50\n",
      "104 20\n",
      "105 20\n",
      "106 10\n",
      "107 10\n",
      "108 10\n",
      "109 10\n",
      "110 10\n",
      "111 10\n",
      "112 10\n",
      "113 10\n",
      "114 10\n",
      "115 10\n",
      "116 10\n",
      "117 10\n",
      "118 5\n",
      "119 5\n",
      "120 10\n",
      "121 10\n",
      "122 10\n",
      "123 10\n",
      "124 10\n",
      "125 10\n",
      "126 10\n",
      "127 1\n",
      "128 1\n",
      "129 1\n",
      "130 1\n",
      "131 1\n",
      "132 1\n",
      "133 1\n",
      "134 1\n",
      "135 50\n",
      "136 1\n",
      "137 1\n",
      "138 1\n",
      "139 1\n",
      "140 1\n",
      "141 1\n",
      "142 1\n",
      "143 1\n",
      "144 1\n",
      "145 1\n",
      "146 1\n",
      "147 1\n",
      "148 20\n",
      "149 20\n",
      "150 20\n",
      "151 20\n",
      "152 20\n",
      "153 20\n",
      "154 20\n",
      "155 20\n",
      "156 20\n",
      "157 20\n",
      "158 20\n",
      "159 20\n",
      "160 20\n",
      "161 20\n",
      "162 20\n",
      "163 20\n",
      "164 20\n",
      "165 20\n",
      "166 20\n",
      "167 20\n",
      "168 20\n",
      "169 20\n",
      "170 20\n",
      "171 20\n",
      "172 20\n",
      "173 20\n",
      "174 20\n",
      "175 20\n",
      "176 20\n",
      "177 20\n",
      "178 20\n",
      "179 20\n",
      "180 5\n",
      "181 50\n",
      "182 20\n",
      "183 20\n",
      "184 20\n",
      "185 2\n",
      "186 2\n",
      "187 2\n",
      "188 2\n",
      "189 2\n",
      "190 2\n",
      "191 2\n",
      "192 2\n",
      "193 2\n",
      "194 2\n",
      "195 2\n",
      "196 2\n",
      "197 2\n",
      "198 2\n",
      "199 2\n",
      "200 2\n",
      "201 2\n",
      "202 2\n",
      "203 2\n",
      "204 2\n",
      "205 2\n",
      "206 2\n",
      "207 2\n",
      "208 2\n",
      "209 2\n",
      "210 2\n",
      "211 2\n",
      "212 2\n",
      "213 2\n",
      "214 2\n",
      "215 2\n",
      "216 2\n",
      "217 2\n",
      "218 2\n",
      "219 2\n",
      "220 2\n",
      "221 2\n",
      "222 500\n",
      "223 500\n",
      "224 500\n",
      "225 20\n",
      "226 500\n",
      "227 500\n",
      "228 500\n",
      "229 500\n",
      "230 500\n",
      "231 500\n",
      "232 500\n",
      "233 500\n",
      "234 500\n",
      "235 500\n",
      "236 500\n",
      "237 2\n",
      "238 500\n",
      "239 500\n",
      "240 500\n",
      "241 500\n",
      "242 500\n",
      "243 500\n",
      "244 500\n",
      "245 500\n",
      "246 500\n",
      "247 10\n",
      "248 500\n",
      "249 500\n",
      "250 500\n",
      "251 500\n",
      "252 500\n",
      "253 500\n",
      "254 500\n",
      "255 500\n",
      "256 500\n",
      "257 500\n",
      "258 500\n",
      "259 50\n",
      "260 50\n",
      "261 50\n",
      "262 50\n",
      "263 50\n",
      "264 50\n",
      "265 50\n",
      "266 50\n",
      "267 50\n",
      "268 50\n",
      "269 50\n",
      "270 50\n",
      "271 50\n",
      "272 50\n",
      "273 50\n",
      "274 50\n",
      "275 50\n",
      "276 50\n",
      "277 50\n",
      "278 50\n",
      "279 20\n",
      "280 50\n",
      "281 50\n",
      "282 50\n",
      "283 50\n",
      "284 50\n",
      "285 50\n",
      "286 50\n",
      "287 50\n",
      "288 50\n",
      "289 50\n",
      "290 50\n",
      "291 50\n",
      "292 50\n",
      "293 50\n",
      "294 50\n",
      "295 50\n",
      "296 5\n",
      "297 5\n",
      "298 5\n",
      "299 5\n",
      "300 5\n",
      "301 100\n",
      "302 5\n",
      "303 5\n",
      "304 2\n",
      "305 10\n",
      "306 5\n",
      "307 5\n",
      "308 5\n",
      "309 5\n",
      "310 5\n",
      "311 5\n",
      "312 5\n",
      "313 5\n",
      "314 5\n",
      "315 2\n",
      "316 5\n",
      "317 5\n",
      "318 5\n",
      "319 50\n",
      "320 5\n",
      "321 5\n",
      "322 5\n",
      "323 1\n",
      "324 5\n",
      "325 5\n",
      "326 5\n",
      "327 50\n",
      "328 5\n",
      "329 5\n",
      "330 5\n",
      "331 50\n",
      "332 5\n",
      "[1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000\n",
      " 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000\n",
      " 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000\n",
      " 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000  100  100  100\n",
      "  100  100  100  100  100  100  100  100  100  100  100  100  100  100\n",
      "  100  100  100  100  100  100  100  100  100  100  100  100  100  100\n",
      "  100  100  100  100  100  100   10   10   10   10   10   10   10   10\n",
      "   10   10   10   10   10   10   10   10   10   10   10   10   10   10\n",
      "   10   10   10   10   10   10   10   10   10   10   10   10   10   10\n",
      "   10    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1   20   20   20   20   20   20\n",
      "   20   20   20   20   20   20   20   20   20   20   20   20   20   20\n",
      "   20   20   20   20   20   20   20   20   20   20   20   20   20   20\n",
      "   20   20   20    2    2    2    2    2    2    2    2    2    2    2\n",
      "    2    2    2    2    2    2    2    2    2    2    2    2    2    2\n",
      "    2    2    2    2    2    2    2    2    2    2    2    2  500  500\n",
      "  500  500  500  500  500  500  500  500  500  500  500  500  500  500\n",
      "  500  500  500  500  500  500  500  500  500  500  500  500  500  500\n",
      "  500  500  500  500  500  500  500   50   50   50   50   50   50   50\n",
      "   50   50   50   50   50   50   50   50   50   50   50   50   50   50\n",
      "   50   50   50   50   50   50   50   50   50   50   50   50   50   50\n",
      "   50   50    5    5    5    5    5    5    5    5    5    5    5    5\n",
      "    5    5    5    5    5    5    5    5    5    5    5    5    5    5\n",
      "    5    5    5    5    5    5    5    5    5    5    5]\n",
      "89.7897897897898\n"
     ]
    }
   ],
   "source": [
    "# p=model.predict(test_img,batch_size=None,verbose=0,steps=None)\n",
    "\n",
    "save_csv={}\n",
    "for i in range(len(p)):\n",
    "    if p[i].argmax()==0:\n",
    "        save_csv[i]=1\n",
    "        print(i,\"1\")\n",
    "    elif p[i].argmax()==1:\n",
    "        save_csv[i]=2\n",
    "        print(i,\"2\")\n",
    "    elif p[i].argmax()==2:\n",
    "        save_csv[i]=5\n",
    "        print(i,\"5\")\n",
    "    elif p[i].argmax()==3:\n",
    "        save_csv[i]=10\n",
    "        print(i,\"10\")\n",
    "    elif p[i].argmax()==4:\n",
    "        save_csv[i]=20\n",
    "        print(i,\"20\")\n",
    "    elif p[i].argmax()==5:\n",
    "        save_csv[i]=50\n",
    "        print(i,\"50\")\n",
    "    elif p[i].argmax()==6:\n",
    "        save_csv[i]=100\n",
    "        print(i,\"100\")\n",
    "    elif p[i].argmax()==7:\n",
    "        save_csv[i]=500\n",
    "        print(i,\"500\")\n",
    "    elif p[i].argmax()==8:\n",
    "        save_csv[i]=1000\n",
    "        print(i,\"1000\")\n",
    "        \n",
    "path=\"bangla-money/Testing\"\n",
    "test_files=[os.path.join(path,f) for f in os.listdir(path) if f.endswith('.jpg')]\n",
    "sps=[im.replace(path+'\\\\','') for im in test_files]\n",
    "y_actual=np.array([ sp[:sp.index('_')] for sp in sps], dtype=int)\n",
    "print(y_actual)\n",
    "\n",
    "a=0\n",
    "for i in range(len(save_csv)):\n",
    "    if save_csv[i]==y_actual[i]:\n",
    "        a+=1\n",
    "b=(float(a)/len(save_csv))*100\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.996996996997\n"
     ]
    }
   ],
   "source": [
    "# a=0\n",
    "# for i in range(len(save_csv)):\n",
    "#     if save_csv[i]==y_actual[i]:\n",
    "#         a+=1\n",
    "# b=(float(a)/len(save_csv))*100\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model save\n",
    "# model_name=\"CNN_\"+str(b)+\"_.hdf5\"\n",
    "# keras.models.save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
